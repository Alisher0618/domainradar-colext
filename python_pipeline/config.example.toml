[connection]
brokers = ["aiokafka://localhost:9092"]
use_ssl = false

[connection.ssl]
ca_file = "/path/to/ca.pem"
server_verification_required = true
client_cert_file = "/path/to/client_certificate.pem"
client_key_file = "/path/to/client_key.pem"
client_key_password = "password for the private key"
check_hostname = true

[faust]
# All keys from this section will be passed directly to the faust.App constructor
# See common/util.py:make_app for keys that cannot be set from this configuration
# See https://faust-streaming.github.io/faust/userguide/settings.html#guide-settings
producer_compression_type = "zstd"

[rdap_dn]
# -- Available in all components -- #
# Faust app ID
app_id = "domrad-rdap-dn"
# Faust debug mode
debug = false
# The number of worker threads that process input entries (available in all components)
concurrency = 4
# --------------------------------- #

# RDAP request timeout (seconds)
http_timeout = 5
# Allow max `limiter_concurrency` requests in `limiter_window` seconds for a single RDAP endpoint.
# Uses the leaky bucket algorithm. See https://aiolimiter.readthedocs.io/ for details on the limiter.
# This is the base setting, it can be overriden per-endpoint.
limiter_concurrency = 10
limiter_window = 30
# When true, the input entries will immediately fail with the LOCAL_RATE_LIMIT error if the
# local rate limiter is empty. Otherwise, the entries will be queued (indefinitely) until the limiter is free.
immediate_local_rate_limiter = false

[rdap_dn.limiter_overrides]
# Example of overriding the limiter settings for a specific RDAP endpoint.
# The key may be the full URL of the endpoint or the target TLD.
# The value is an array with two values: [ limiter concurrency, limiter window ]
"https://rdap.verisign.com/com/v1/" = [10, 120]
"cz" = [50, 50]

[rdap_ip]
app_id = "domrad-rdap-ip"
# RDAP request timeout (seconds)
http_timeout = 5
# Same as in rdap_dn.
limiter_concurrency = 10
limiter_window = 30
immediate_local_rate_limiter = false

[rdap_ip.limiter_overrides]
# Here, the keys must only contain the full URL of the RDAP endpoint.
# See https://data.iana.org/rdap/ipv4.json and https://data.iana.org/rdap/ipv6.json.
"https://rdap.lacnic.net/rdap/" = [5, 60]

[rtt]
app_id = "domrad-rtt"
ping_count = 5
privileged_mode = false

[dns]
app_id = "domrad-dns"
# The DNS servers to use for fallback resolution if the primary NS does not respond.
dns_servers = ["195.113.144.194", "195.113.144.233"]
# A single DNS query timeout.
timeout = 5
# Whether to query the fallback DNS servers in a round-robin fashion.
rotate_nameservers = false
# DNS record types to query for (supported types: A, AAAA, CNAME, MX, NS, TXT).
types_to_scan = ["A", "AAAA", "CNAME", "MX", "NS", "TXT"]
# DNS record types to further process IPs from (supported types: A, AAAA, CNAME, MX, NS).
types_to_process_IPs_from = ["A", "AAAA", "CNAME"]
# Maximum number of retries for a single DNS query in case of a timeout.
max_record_retries = 2
# Log level for the DNS scanner.
scanner_log_level = "INFO"
# EXPERIMENTAL: Use a single UDP socket instance for all DNS queries. If changed to false,
# each UDP query will open a new socket and close it after the response is received.
use_one_socket = true

[zone]
app_id = "domrad-zone"
# The DNS servers to use for queries needed for zone resolution.
dns_servers = ["195.113.144.194", "195.113.144.233"]
# A single DNS query timeout.
timeout = 5
# Whether to query the DNS servers in a round-robin fashion.
rotate_nameservers = true

[extractor]
app_id = "domrad-extractor"
data_dir = "/path/to/data"
# Number of records to collect in a buffer and process at once.
# This should be fairly high, according to the input rate.
# The downside of batching is that in case of an unhandled exception,
# the whole batch is lost.
batch_size = 100
# Maximum time (in seconds) to wait for a full batch before processing.
# In other words, the extractor will always process its current buffer
# `batch_timeout` seconds after the last processed one, even if it's not full.
batch_timeout = 5

[classifier-unit]
app_id = "domrad-classifier-unit"
# If not set, the directory embedded with the "domainradar-clf" project will be used
model_path = "/path/to/models"
# This controls the "batching of batches" coming from the feature extractor.
# It is recommended to only batch the data on the feature extractor level.
batch_size = 1
batch_timeout = 0